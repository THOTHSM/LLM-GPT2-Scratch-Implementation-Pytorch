{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oCkEGUMHZVP",
        "outputId": "60b4c83a-f3ec-4151-cbfe-81de9e6e7fcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "gvvrSB8oFdnr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "PBHev9iKF1Dg"
      },
      "outputs": [],
      "source": [
        "class Multi_Head_Attention(torch.nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout_rate, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0),\"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "\n",
        "        self.W_query = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "        self.out_proj = torch.nn.Linear(d_out, d_out)\n",
        "\n",
        "        self.Dropout = torch.nn.Dropout(dropout_rate)\n",
        "\n",
        "        self.register_buffer(\"mask\",torch.triu(torch.ones(context_length, context_length),diagonal=1))\n",
        "\n",
        "    def forward(self,x):\n",
        "        batch , number_of_tokens , d_in = x.shape\n",
        "\n",
        "        self.query = self.W_query(x)\n",
        "        self.key = self.W_key(x)\n",
        "        self.value = self.W_value(x)\n",
        "\n",
        "        query = self.query.view(batch,number_of_tokens,self.num_heads,self.head_dim) #Adjusting size for all heads\n",
        "        key = self.key.view(batch,number_of_tokens,self.num_heads,self.head_dim)\n",
        "        value = self.value.view(batch,number_of_tokens,self.num_heads,self.head_dim)\n",
        "\n",
        "        key = key.transpose(1, 2)\n",
        "        query = query.transpose(1, 2)\n",
        "        value = value.transpose(1, 2)\n",
        "\n",
        "        attention_score = query @ key.transpose(2,3)\n",
        "\n",
        "         # Converting to true or false matrix and shaping to number of tokens\n",
        "        mask_bool = self.mask.bool()[:number_of_tokens, :number_of_tokens]\n",
        "\n",
        "        attention_score.masked_fill_(mask_bool,-torch.inf)\n",
        "\n",
        "        attention_weights = torch.softmax(attention_score/self.head_dim**0.5,dim=-1)\n",
        "\n",
        "        attention_weights = self.Dropout(attention_weights)\n",
        "\n",
        "        context_vector = (attention_weights @ value).transpose(1,2)\n",
        "\n",
        "        context_vector = context_vector.contiguous().view(batch,number_of_tokens,self.d_out)\n",
        "        context_vector = self.out_proj(context_vector)\n",
        "        return context_vector\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "fSw8g7MUGJnf"
      },
      "outputs": [],
      "source": [
        "class Layer_normalization(torch.nn.Module):\n",
        "    def __init__(self,emb_dim):\n",
        "        super().__init__()\n",
        "        self.epsilon = 1e-5\n",
        "        self.scale = torch.nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = torch.nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self,x):\n",
        "        mean = x.mean(dim=-1,keepdim=True)\n",
        "        variance = x.var(dim=-1,keepdim=True,unbiased=False)\n",
        "        norm_x = (x-mean)/torch.sqrt(variance+self.epsilon)\n",
        "        return self.scale*norm_x+self.shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "o3uYLquMGMk-"
      },
      "outputs": [],
      "source": [
        "class Gelu(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self,x): # GELU activation function:\n",
        "        # f(x) = 0.5 * x * (1 + tanh(sqrt(2/pi) * (x + 0.044715 * x^3)))\n",
        "        return 0.5*x*(1+torch.tanh(torch.sqrt(torch.tensor(2.0/torch.pi))*(x+0.044715*torch.pow(x,3))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "VX749HksGN32"
      },
      "outputs": [],
      "source": [
        "class Feed_forward(torch.nn.Module):\n",
        "    def __init__(self,cfg):\n",
        "        super().__init__()\n",
        "        self.layers = torch.nn.Sequential(\n",
        "            torch.nn.Linear(cfg[\"emb_dim\"],4*cfg[\"emb_dim\"]),\n",
        "            Gelu(),\n",
        "            torch.nn.Linear(4*cfg[\"emb_dim\"],cfg[\"emb_dim\"])\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "UpMWkCi6GXJO"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(torch.nn.Module):\n",
        "    def __init__(self,cfg):\n",
        "        super().__init__()\n",
        "\n",
        "        self.att = Multi_Head_Attention( d_in=cfg[\"emb_dim\"],\n",
        "                                        d_out=cfg[\"emb_dim\"],\n",
        "                                        context_length=cfg[\"context_length\"],\n",
        "                                        dropout_rate=cfg[\"drop_rate\"],\n",
        "                                        num_heads=cfg[\"n_heads\"],\n",
        "                                        qkv_bias=cfg[\"qkv_bias\"])\n",
        "\n",
        "        self.layer_norm1 = Layer_normalization(emb_dim=cfg[\"emb_dim\"])\n",
        "\n",
        "        self.layer_norm2 = Layer_normalization(emb_dim=cfg[\"emb_dim\"])\n",
        "\n",
        "        self.feed_forward = Feed_forward(cfg=cfg)\n",
        "\n",
        "        self.dropout = torch.nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self,x):\n",
        "        shortcut =x\n",
        "        x = self.layer_norm1(x)\n",
        "        x = self.att(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x+shortcut\n",
        "        shortcut = x\n",
        "        x = self.layer_norm2(x)\n",
        "        x = self.feed_forward(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x + shortcut\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "lHNoaYmIGjzG"
      },
      "outputs": [],
      "source": [
        "class GPTModel(torch.nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "\n",
        "        self.tok_emb = torch.nn.Embedding(cfg[\"vocab_size\"],cfg[\"emb_dim\"])\n",
        "        self.pos_emb = torch.nn.Embedding(cfg[\"context_length\"],cfg[\"emb_dim\"])\n",
        "        self.drop_emb = torch.nn.Dropout(cfg[\"drop_rate\"])\n",
        "        self.transformer_blocks = torch.nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "        self.final_norm = Layer_normalization(cfg[\"emb_dim\"])\n",
        "        self.output_head = torch.nn.Linear(cfg[\"emb_dim\"],cfg[\"vocab_size\"],bias=False)\n",
        "\n",
        "    def forward(self,id_idx):\n",
        "        batch,seq_len = id_idx.shape\n",
        "        token_embeded = self.tok_emb(id_idx)\n",
        "        position_embeded = self.pos_emb(torch.arange(seq_len, device= id_idx.device))\n",
        "        x = token_embeded + position_embeded\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.transformer_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.output_head(x)\n",
        "        return logits\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "AXWdXDLjLC9R"
      },
      "outputs": [],
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,   # Vocabulary size\n",
        "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
        "    \"emb_dim\": 768,        # Embedding dimension\n",
        "    \"n_heads\": 12,         # Number of attention heads\n",
        "    \"n_layers\": 12,        # Number of layers\n",
        "    \"drop_rate\": 0.1,      # Dropout rate\n",
        "    \"qkv_bias\": False      # Query-key-value bias\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "Ml7YfPIOK7-B"
      },
      "outputs": [],
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "ZGWKWm54G40G"
      },
      "outputs": [],
      "source": [
        "class CategoricalCrossEntropy:\n",
        "    def __init__(self, target):\n",
        "        self.target_flat = target.flatten()\n",
        "\n",
        "    def loss(self, logits_matrix):\n",
        "        logits_flat = logits_matrix.view(-1,logits_matrix.shape[-1])\n",
        "        log_probs = torch.log_softmax(logits_flat, dim=-1)\n",
        "        selected_log_probs = log_probs[torch.arange(logits_flat.size(0)),self.target_flat]\n",
        "        self.loss = -torch.sum(selected_log_probs) /logits_matrix.shape[0]\n",
        "        return self.loss\n",
        "\n",
        "    def perplexity(self):\n",
        "        return torch.exp(self.loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "BD1KIqhWG_F3"
      },
      "outputs": [],
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "        text_data = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj6psS1gHImH",
        "outputId": "1134486b-b129-44c0-c53f-781f115d94ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I HAD always thought\n"
          ]
        }
      ],
      "source": [
        "print(text_data[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTPgVxI6HLQn",
        "outputId": "2845bb3a-6882-41ea-8e13-f4f30af4a99b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charector : 20479\n",
            "Token  : 5145\n"
          ]
        }
      ],
      "source": [
        "print(f\"Charector : {len(text_data)}\")\n",
        "tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
        "tokens = tokenizer.encode(text_data)\n",
        "print(f\"Token  : {len(tokens)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "UiefSUGfIPk3"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset ,DataLoader\n",
        "\n",
        "class GPTDataset(Dataset):\n",
        "    def __init__(self,text_data,tokenizer,max_length,stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        tokens = tokenizer.encode(text_data, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        for i in range(0,len(tokens)-max_length,stride):\n",
        "\n",
        "            input_chunk = tokens[i:i+max_length]\n",
        "            target_chunk = tokens[i+1:i+max_length+1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return  self.input_ids[index],self.target_ids[index]\n",
        "\n",
        "\n",
        "def dataloader_dataset(text_data, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "    dataset = GPTDataset(text_data,tokenizer,max_length,stride)\n",
        "    dataloader = DataLoader(dataset,batch_size=batch_size,shuffle=shuffle,drop_last=drop_last,num_workers=num_workers)\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpfiRD2dIU1n",
        "outputId": "0b2f1b56-4c8e-428b-8778-921f47ed972e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16383 4096\n"
          ]
        }
      ],
      "source": [
        "trian_percent = 0.8\n",
        "index_train_val = int(len(text_data)*trian_percent)\n",
        "\n",
        "train_data = text_data[:index_train_val]\n",
        "\n",
        "val_data  = text_data[index_train_val:]\n",
        "print(len(train_data),len(val_data))\n",
        "\n",
        "train_data_loader = dataloader_dataset(train_data,batch_size=2,max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "                                          stride=GPT_CONFIG_124M[\"context_length\"],drop_last=True,shuffle=True,num_workers=0)\n",
        "\n",
        "val_data_loader = dataloader_dataset(val_data,batch_size=2,max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "                                          stride=GPT_CONFIG_124M[\"context_length\"],drop_last=True,shuffle=True,num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTMi_5ewIcen",
        "outputId": "c66ea2fe-52b7-4553-e295-9399e414089e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "\n",
            "Validation loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "8\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "for x, y in train_data_loader:\n",
        "    print(x.shape, y.shape)\n",
        "\n",
        "print(\"\\nValidation loader:\")\n",
        "for x, y in val_data_loader:\n",
        "    print(x.shape, y.shape)\n",
        "\n",
        "print(len(train_data_loader))\n",
        "print(len(val_data_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "M760X2cBIh73"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOfX5C6NIjXP",
        "outputId": "5908c9e9-52ab-4dd0-b939-9d020fe33909"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 10.987749457359314\n",
            "Validation loss: 10.999006748199463\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Note:\n",
        "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
        "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
        "# However, the resulting loss values may be slightly different.\n",
        "\n",
        "#if torch.cuda.is_available():\n",
        "#    device = torch.device(\"cuda\")\n",
        "#elif torch.backends.mps.is_available():\n",
        "#    device = torch.device(\"mps\")\n",
        "#else:\n",
        "#    device = torch.device(\"cpu\")\n",
        "#\n",
        "# print(f\"Using {device} device.\")\n",
        "\n",
        "\n",
        "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
        "\n",
        "\n",
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
        "\n",
        "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
        "    train_loss = calc_loss_loader(train_data_loader, model, device)\n",
        "    val_loss = calc_loss_loader(val_data_loader, model, device)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxIIlEnPLJCu",
        "outputId": "fe9a3f19-fa0d-44ba-d7ce-1f808527cc0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "kTOHjoOyMWb6"
      },
      "outputs": [],
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "jesDKY46MQbG"
      },
      "outputs": [],
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "    if device is not None:\n",
        "        idx = idx.to(device)\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # New: Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        # New: Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "nPJSvgReL7oh"
      },
      "outputs": [],
      "source": [
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "sB77mhmnLYbR"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "MKVQE9FnLZ4y"
      },
      "outputs": [],
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate(model=model,idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        "                              max_new_tokens=15,context_size=GPT_CONFIG_124M[\"context_length\"],top_k=25,\n",
        "                                temperature=1.4)\n",
        "\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "Tnyr1mYiMf0D"
      },
      "outputs": [],
      "source": [
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ky2eWM_Mn2a",
        "outputId": "f5d37433-95c2-45ca-98b3-de575f98a9f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 9.876, Val loss 10.079\n",
            "Ep 1 (Step 000005): Train loss 8.095, Val loss 8.349\n",
            "Every effort moves you, a   I   ,,. a you a I\n",
            "Ep 2 (Step 000010): Train loss 6.595, Val loss 7.220\n",
            "Ep 2 (Step 000015): Train loss 5.943, Val loss 6.841\n",
            "Every effort moves you.  \" up had it was he was a,.. \n",
            "Ep 3 (Step 000020): Train loss 5.244, Val loss 6.805\n",
            "Every effort moves you with a, all with a was not--; and him on, as\n",
            "Ep 4 (Step 000025): Train loss 4.598, Val loss 6.763\n",
            "Ep 4 (Step 000030): Train loss 4.102, Val loss 6.735\n",
            "Every effort moves you of--is and my at the course of the a was that--as\n",
            "Ep 5 (Step 000035): Train loss 3.605, Val loss 6.625\n",
            "Every effort moves you know,\"! the of by a fashionable,\" he was not with me,\n",
            "Ep 6 (Step 000040): Train loss 3.021, Val loss 6.590\n",
            "Ep 6 (Step 000045): Train loss 2.598, Val loss 6.624\n",
            "Every effort moves you?\"   His my hostess was when, but handsome me.\n",
            "Ep 7 (Step 000050): Train loss 2.218, Val loss 6.685\n",
            "Ep 7 (Step 000055): Train loss 1.638, Val loss 6.691\n",
            "Every effort moves you in the reason to me't to have to's an fact-room.\n",
            "Ep 8 (Step 000060): Train loss 1.397, Val loss 6.743\n",
            "Every effort moves you?\" Gisburn's the mant of his life the house from the reason\n",
            "Ep 9 (Step 000065): Train loss 0.936, Val loss 6.824\n",
            "Ep 9 (Step 000070): Train loss 0.719, Val loss 6.860\n",
            "Every effort moves you say to see his pictures with equ insensible to the fact with equanim\n",
            "Ep 10 (Step 000075): Train loss 0.545, Val loss 6.943\n",
            "Every effort moves you know he chucked his own for he G he--I told me in\n",
            "Training completed in 20.03 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_data_loader, val_data_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Note:\n",
        "# Uncomment the following code to show the execution time\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "FE7bgEZ0WpNz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "cf192e27-0800-41e4-d01a-d501c659b9eb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "soKq-RkUgVQc"
      },
      "outputs": [],
      "source": [
        "!pip3 install tensorflow>=2.15.0 tqdm>=4.66"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "uVWUN6oggpMt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "999c80a6-0373-4835-cb7f-3b3e450ba578"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.17.1\n",
            "tqdm version: 4.66.6\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tqdm\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"tqdm version:\", tqdm.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "oXBuXohQgwuF"
      },
      "outputs": [],
      "source": [
        "from gpt_download3 import download_and_load_gpt2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "A2K938Njlz-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90c5b67a-90c9-4982-a9f5-2ab7e8282b05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
            "File already exists and is up-to-date: gpt2/124M/hparams.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
            "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "aBGyaHEFmbRg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b8b89c8-37c0-40fb-b96b-8ca870c62426"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
            "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
          ]
        }
      ],
      "source": [
        "print(\"Settings:\", settings)\n",
        "print(\"Parameter dictionary keys:\", params.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "UUaBQ3gpmfV3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e26136c-e264-405d-83cd-c6037a8dcd0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
            "   0.04531523]\n",
            " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
            "   0.04318958]\n",
            " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
            "  -0.08785918]\n",
            " ...\n",
            " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
            "  -0.06952604]\n",
            " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
            "  -0.02245961]\n",
            " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
            "   0.12067825]]\n",
            "Token embedding weight tensor dimensions: (50257, 768)\n"
          ]
        }
      ],
      "source": [
        "print(params[\"wte\"])\n",
        "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "fl5mAOv0mhxX"
      },
      "outputs": [],
      "source": [
        "# Define model configurations in a dictionary for compactness\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "# Copy the base configuration and update with specific model settings\n",
        "model_name = \"gpt2-small (124M)\"  # Example model name\n",
        "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
        "NEW_CONFIG.update(model_configs[model_name])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "BpottYhTmnmn"
      },
      "outputs": [],
      "source": [
        "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
        "gpt = GPTModel(NEW_CONFIG)\n",
        "gpt.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "jbdyJUA6mrfn"
      },
      "outputs": [],
      "source": [
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "kN9fOMgymvjY"
      },
      "outputs": [],
      "source": [
        "def load_weights_into_gpt(gpt, params):\n",
        "    # Load position and token embeddings\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        # Split and assign query, key, and value weights\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"w\"], 3, axis=-1)\n",
        "        gpt.transformer_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.transformer_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.transformer_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.transformer_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.transformer_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.transformer_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        # Split and assign query, key, and value biases\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"b\"], 3, axis=-1)\n",
        "        gpt.transformer_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.transformer_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.transformer_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.transformer_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.transformer_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.transformer_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        # Load attention output projection\n",
        "        gpt.transformer_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.transformer_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.transformer_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.transformer_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        # Load feed-forward layers\n",
        "        gpt.transformer_blocks[b].feed_forward.layers[0].weight = assign(\n",
        "            gpt.transformer_blocks[b].feed_forward.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.transformer_blocks[b].feed_forward.layers[0].bias = assign(\n",
        "            gpt.transformer_blocks[b].feed_forward.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.transformer_blocks[b].feed_forward.layers[2].weight = assign(\n",
        "            gpt.transformer_blocks[b].feed_forward.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.transformer_blocks[b].feed_forward.layers[2].bias = assign(\n",
        "            gpt.transformer_blocks[b].feed_forward.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        # Load LayerNorm parameters\n",
        "        gpt.transformer_blocks[b].layer_norm1.scale = assign(\n",
        "            gpt.transformer_blocks[b].layer_norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.transformer_blocks[b].layer_norm1.shift = assign(\n",
        "            gpt.transformer_blocks[b].layer_norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.transformer_blocks[b].layer_norm2.scale = assign(\n",
        "            gpt.transformer_blocks[b].layer_norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.transformer_blocks[b].layer_norm2.shift = assign(\n",
        "            gpt.transformer_blocks[b].layer_norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    # Load final LayerNorm and output head\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.output_head.weight = assign(gpt.output_head.weight, params[\"wte\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "vtOmDIlYm0QH"
      },
      "outputs": [],
      "source": [
        "load_weights_into_gpt(gpt, params)\n",
        "gpt.to(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "ZFvBYVYinX8X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47dce148-2955-492f-bb3f-7b5d5ac1ccd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you toward an equal share for each vote plus half. Inequality is often not an accurate representation of human worth; to know the\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=gpt,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
        "    max_new_tokens=25,\n",
        "    context_size=NEW_CONFIG[\"context_length\"],\n",
        "    top_k=50,\n",
        "    temperature=1.5\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}